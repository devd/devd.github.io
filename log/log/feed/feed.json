{
  "version": "https://jsonfeed.org/version/1",
  "title": "Dev&#39;s log",
  "home_page_url": "https://devd.me/log/",
  "feed_url": "https://devd.me/log/feed/feed.json",
  "description": "Thoughts on security engineering",
  "author": {
    "name": "Devdatta Akhawe",
    "url": ""
  },
  "items": [{
      "id": "https://devd.me/log/posts/startup-security/",
      "url": "https://devd.me/log/posts/startup-security/",
      "title": "Early Security for Startups",
      "content_html": "<p><em>I once read blogging advice:</em> <em>if someone asks you something, write it as a blog post and soon you will have a blog. One advice I am often asked is “I am a new startup; how should I approach security?” Here goes my attempt, based on</em> <a href=\"https://linkedin.com/in/devdattaakhawe\"><em>my experience</em></a> <em>working at and advising hypergrowth companies. Please send me your thoughts and feedback!</em></p>\n<h1 id=\"who-is-this-for%3F\">Who is this for? <a class=\"direct-link\" href=\"#who-is-this-for%3F\">#</a></h1>\n<p>This is advice for early-stage startups without security teams (the post ends with advice on your first security hire!). It focuses on the basics for an early-stage startup. If you already have a security team, listen to the team!</p>\n<p>Most of my experience has been in product-led enterprise SaaS businesses. This guide is likely useful to such startups. If you are working on things like social network or a crypto product, your threat model and priorities are very different, and this guide is likely not correct for you. That said, it might still be useful!</p>\n<p>The guide also assumes that the founders and early members of the team already care about security. As an example, if you are not already using HTTPS everywhere, if you are not already on a framework like Rails that auto-escapes SQL queries, and so on, this guide is likely not for you.</p>\n<p>This guide is also <em>prescriptive</em>: in addition to broad advice, it specifies tools and vendors to use, as founders have found this very useful. I make no attempt to be unbiased here: these are products I like and/or have some form of connection or interest in.</p>\n<h1 id=\"what-is-security%3F\">What is security? <a class=\"direct-link\" href=\"#what-is-security%3F\">#</a></h1>\n<p>An easy way to come up with what a team without a security team should do is to start with understanding what a security team, if present, would do. I think of a security team’s role in 3 categories (<a href=\"https://about.gitlab.com/handbook/engineering/security/\">inspired by</a> <a href=\"https://about.gitlab.com/handbook/engineering/security/\">GitLab’s docs</a>):</p>\n<ol>\n<li>Protect the company from data breaches:  Security teams are primarily responsible for preventing unauthorized access to data, broadly construed. A security team will help contextualize and prioritize security risk to the company and manage mitigations.</li>\n<li>Secure the product:  a software company ships products, and a security team will often be ensuring that these products do not have technical vulnerabilities (typically, as part of the product security sub-function).</li>\n<li>Customer Assurance: It’s not enough for you and your products to be secure; your customers also need to trust you are secure. This involves things like compliance certifications, answering customer security questionnaires, and helping your customers use your product securely.</li>\n</ol>\n<p>Let’s discuss each category in detail, especially in the context of an early-stage startup.</p>\n<h1 id=\"protect-the-company-from-data-breaches\">Protect the company from data breaches <a class=\"direct-link\" href=\"#protect-the-company-from-data-breaches\">#</a></h1>\n<p>The <em>possibility</em> of data breaches is everywhere and the only way to prevent all data breaches is stop doing anything. Instead, a security team focuses on <em>risk reduction.</em> A security team’s primary job is to a) identify and prioritize data breach risks to the business and b) manage/mitigate them through technology and/or processes.</p>\n<h2 id=\"what-is-risk%3F\">What is risk? <a class=\"direct-link\" href=\"#what-is-risk%3F\">#</a></h2>\n<p>Risk is usually defined as the product of probability and impact: e.g., high probability and high impact issues are the highest risk. While the math helps, I find it easiest to explain risk with a story.</p>\n<p>I love hiking and I once hiked up Mt. Kilimanjaro. When I mention hiking Kili, people often ask me if the mountain was scary/risky. Truth is, mountain was fun, exhilarating, and probably one of the healthiest things I did that year. Statistically, the riskiest part of the trip was the car ride to the mountain and back.</p>\n<p>Security for early startups is similar: while you are doing something unique, most of your risk is due to the everyday hazards that affects everyone. Wear your seatbelt and you will be fine.</p>\n<p>Furthermore, for most startups, the biggest business risk is irrelevance: you don’t get to product market fit and/or you don’t cross the chasm into wide adoption. Hackers are not targeting startups with no users. But there is a “background radiation” of malicious activity on the internet targeting every modern software company that everyone needs to defend against. This background or latent risk is behind most breaches that you hear about. It is rare and exceptional for a startup to be specifically targeted persistently; rather, they get compromised by opportunistic criminals.</p>\n<h2 id=\"security-risks-for-a-startup\">Security Risks for a startup <a class=\"direct-link\" href=\"#security-risks-for-a-startup\">#</a></h2>\n<p><strong>If you take</strong> <em><strong>one thing</strong></em> <strong>away from this doc</strong>, it is to focus on the common source of breaches. While the security and compliance of your product itself is important, what will get you hacked is what gets everyone else. That latest complicated side-channel exploit you read on HackerNews is unlikely to affect your startup.</p>\n<p>If I am asked what the most common source of large breaches in the last few years are, it's</p>\n<ol>\n<li>Ransomware</li>\n<li>Cloud misconfiguration/leak</li>\n<li>Credential compromise via phishing, password reuse, etc.</li>\n</ol>\n<p>Let's go through mitigating these risks at a startup in turn.</p>\n<h2 id=\"ransomware\">Ransomware <a class=\"direct-link\" href=\"#ransomware\">#</a></h2>\n<p>For the typical startup, ransomware is unlikely to be a large risk since most startups have small teams running modern OSes like MacOS with no legacy code. While this can change (MacOS malware is growing!), I do not believe for most startups, MacOS ransomware is an immediate risk worth prioritizing.</p>\n<h2 id=\"cloud-misconfiguration\">Cloud Misconfiguration <a class=\"direct-link\" href=\"#cloud-misconfiguration\">#</a></h2>\n<p>While modern cloud infrastructure is amazing, it’s far too easy to make a mistake and introduce a serious, massive vulnerability that opportunistic criminals will latch on to. <a href=\"https://blog.christophetd.fr/cloud-security-breaches-and-vulnerabilities-2021-in-review/\">Christophe has a fantastic blog post</a> looking back at breaches in 2021: the most common source of breaches are a) static credentials, b) misconfigured data stores that are publicly readable, and  c) SSRF on metadata services.</p>\n<p>Since AWS continues to be the most common cloud provider, I am going to focus on my recommendations for AWS that mitigate the issues above:</p>\n<ul>\n<li>All access in AWS should be through short lived tokens based on role assumption, ideally through your SSO provider (below). Avoid all long-lived credentials (all tooling should support role assumption today; there is almost no reason to have long-lived IAM access keys).</li>\n<li><a href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-control-block-public-access.html\">Block public access</a> to S3 buckets; I also recommend <a href=\"https://www.figma.com/blog/inside-figma-getting-out-of-the-secure-shell/\">using modern tooling like SSM</a> so that no administrative ports (like the ssh port) are listening on the open internet.</li>\n<li><a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/configuring-instance-metadata-options.html\">Disable IMDSv1</a> for existing and all new machines (<a href=\"https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/instance#metadata-options\">terraform config</a>)</li>\n<li>Regularly run a free cloud scanning tool (<a href=\"https://github.com/duo-labs/cloudmapper\">cloudmapper</a>/<a href=\"https://github.com/nccgroup/ScoutSuite\">scoutsuite</a> for AWS or <a href=\"https://simplecspm.com/\">simplecspm for GCP</a>) and check no AWS resources are public on the internet.</li>\n</ul>\n<p>Most of these guidelines are from Scott’s <a href=\"https://summitroute.com/downloads/aws_security_maturity_roadmap-Summit_Route.pdf\">fantastic AWS security roadmap</a> freely available for all to use. Similar guides exist for <a href=\"https://cloud.google.com/docs/enterprise/best-practices-for-enterprise-organizations\">GCP</a> and <a href=\"https://www.coffeehousecoders.org/blog/azure_security_roadmap.html\">Azure</a> (or, Marco has a <a href=\"https://roadmap.cloudsecdocs.com/\">generic one</a>).</p>\n<h2 id=\"credential-stuffing\">Credential Stuffing <a class=\"direct-link\" href=\"#credential-stuffing\">#</a></h2>\n<p>The next most common source of breaches is due to account takeover/compromise by phishing or <a href=\"https://en.wikipedia.org/wiki/Credential_stuffing\">credential stuffing</a> of employees. This is where an employee reuses a password for work and a personal account, and the latter gets hacked. Or an employee is phished.</p>\n<p>By far, the most effective security against this is using a strong, centralized service for login to all applications that enforces <a href=\"https://blog.cloudflare.com/cloudflare-now-supports-security-keys-with-web-authentication-webauthn/#:~:text=But%20where%20WebAuthn%20really%20shines%20is%20its%20particular%20resistance%20to%20phishing%20attacks.\">phish-proof webauthn MFA</a> as the only supported MFA mechanism. Start by requiring all SaaS applications (e.g., Datadog, Github, Zendesk, etc.)  to only allow logins through your identity provider (Google or Okta, typically), instead of using username/password. Next, in your identity provider settings, turn on MFA and enable the options so that only webauthn is supported. Note that every other form of MFA is vulnerable to phishing and webauthn is the only secure MFA mechanism. While a few years ago just MFA was sufficient mitigation from attacks, criminals today have learnt how to phish code-based MFA and/or compromise phone numbers to steal SMS codes.</p>\n<p>In Google Workspaces (the most common identity provider at early startups), this is trivial by <a href=\"https://support.google.com/a/answer/9378686?hl=en\">turning on Advanced Protection</a>. Advanced Protection also enables a few other security settings that can be disruptive—in that case, you can enable the <a href=\"https://support.google.com/a/answer/9176657\">“Only Security Key” option</a> in the Google MFA settings for your organization.</p>\n<p>Enforcing SSO on all applications can be expensive, especially for an early, bootstrapped startup. If you can’t enable SSO, at the minimum use Google sign-in wherever available and use unique, strong passwords on each application (via a password manager) and turn on MFA. Chrome’s inbuilt password manager is free but often doesn’t work as well; I recommend <a href=\"https://1password.com/business/\">1Password</a>.</p>\n<h2 id=\"other-common-risks\">Other Common Risks <a class=\"direct-link\" href=\"#other-common-risks\">#</a></h2>\n<p>Finally, another class of issues is the Magecart-style <a href=\"https://en.wikipedia.org/wiki/Web_skimming#Magecart\">“web skimming”</a> attacks: this is where an attacker compromises third-party JS on your payment page and steals credit card numbers (e.g., <a href=\"https://techcrunch.com/2018/09/11/british-airways-breach-caused-by-credit-card-skimming-malware-researchers-say/\">British Airways</a>). Before ransomware became such a reliable, popular way for criminals to make money, web-skimming attacks were all the rage. While a security team can implement robust defenses later, I recommend only loading JS code from your own servers as much as possible. Note that <a href=\"https://developer.chrome.com/blog/http-cache-partitioning/\">cache partitioning</a> means that loading from a CDN provides limited performance benefit. If you really need to include a third-party hosted JS (like marketing, sales tooling), try <a href=\"https://dropbox.tech/security/csp-third-party-integrations-and-privilege-separation\">using privilege separation to limit blast radius</a>.</p>\n<h1 id=\"secure-the-product\">Secure the product <a class=\"direct-link\" href=\"#secure-the-product\">#</a></h1>\n<p>A software company’s most important job is to ship great products that delight their customers. A good security team helps accelerate this by providing secure guardrails for product development and provides a second pair of eyes on the security risk of new features. Even with organizations with mature security teams, the responsibility for securing a feature lies with product teams: a security team only helps as an additional layer of accountability.</p>\n<p>For an early startup, the absence of a security team means that this second pair of eyes is missing: the responsibility of securing new products falls upon the engineers at a company. But this is like other fundamentals like clean code, reliability, scalability etc.; engineers need to balance product iteration and quality and make reasoned tradeoffs. While this is important, <em>I will stress again</em>: for a relatively new startup, you are far and away more likely to get compromised by phishing and AWS misconfigurations than a nuanced bug in your application. Moreover, it is quite possible that you will pivot and <em>securing the wrong product has tremendous opportunity cost</em>.</p>\n<h2 id=\"authentication-and-login\">Authentication and login <a class=\"direct-link\" href=\"#authentication-and-login\">#</a></h2>\n<p>Authentication is the one thing that every product <em>must</em> implement securely. Mistakes can be <a href=\"https://techcrunch.com/2011/06/20/dropbox-security-bug-made-passwords-optional-for-four-hours/\">embarrassing</a>. For modern products, I recommend relying on <a href=\"https://developers.google.com/identity/\">Google’s Identity services</a>: they have fantastic usability and conversion rates. Google handles tricky issues like abuse detection, account compromise, lockout, recovery, etc. and the default Google libraries are secure by design. As a product, you will have to decide on a reasonable session timeout that works for you but note that long session timeouts (&gt; 3 days) will complicate security for your customers. As an enterprise product, at some point you will likely also need to implement SAML/SCIM support. <a href=\"https://auth0.com/docs/authenticate/protocols/saml/saml-sso-integrations\">Okta/Auth0</a> is a relatively well-known provider that can SAML/SCIM for you—you can either use their managed services or their <a href=\"https://github.com/auth0/\">libraries</a>.</p>\n<p>If you do implement password sign-in, make sure to require email verification, <a href=\"https://dropbox.tech/security/how-dropbox-securely-stores-your-passwords\">store passwords securely</a>, and implement a negative test (i.e., test that the wrong password does not let you log in). The <a href=\"https://github.com/OWASP/ASVS/blob/master/5.0/en/0x11-V2-Authentication.md\">OWASP ASVS page on authentication</a> has a long list of password authentication best practices (<a href=\"https://github.com/OWASP/ASVS/tree/master/5.0/en\">the broader ASVS</a> is a great resource to review for any other features you are building too).</p>\n<h2 id=\"application-security\">Application Security <a class=\"direct-link\" href=\"#application-security\">#</a></h2>\n<p>While there is a long list of potential product security concerns, the good news is that modern frameworks and cloud infrastructure has made shipping secure software orders of magnitude easier than in the past. Modern frameworks like React, Rails, etc. default to secure, features like <a href=\"https://docs.github.com/en/code-security/supply-chain-security/managing-vulnerabilities-in-your-projects-dependencies/about-dependabot-security-updates\">Dependabot (free with Github)</a> and <a href=\"https://docs.aws.amazon.com/AmazonECR/latest/userguide/image-scanning.html\">ECR container scanning (free with AWS)</a> make it easy to monitor and patch all your dependencies. Tools like <a href=\"https://semgrep.dev/pricing\">r2c/semgrep (with its community rules)</a> provide a good baseline of security linting on your code (and can be integrated with a few clicks on Github). A high-quality scanner like Detectify can provide a separate external continuous scan of your application, <a href=\"https://detectify.com/pricing\">again with a few clicks and self-serve signup</a>. I generally recommend turning these on—in addition to the security benefits, all these will also come in very handy for customer assurance, as part of your sales process (discussed below).</p>\n<p>In addition to these generic checks for all web applications, it's also worth taking some time to think about unique risks applicable to your application. Are you shipping an electron app? Then, spend some time with the <a href=\"https://www.electronjs.org/docs/latest/tutorial/security/\">electron security checklist</a>. Does your product allow sharing via links? Read up on <a href=\"https://www.youtube.com/watch?v=6AsVUS79gLw\"></a><a href=\"https://freedom-to-tinker.com/2016/04/14/gone-in-six-characters-short-urls-considered-harmful-for-cloud-services/\">security for short links</a>. Are you <a href=\"https://support-my.plaid.com/hc/en-us/articles/4410324401047-Does-Plaid-have-access-to-my-credentials-\">storing credentials</a>? Carefully design the handling/storage of these credentials. For your product, evaluate what are unique, critical pieces of tech in your stack and take a couple of hours to look for the relevant project/tool’s security configuration advice (if you can’t find it, ask a security engineer you trust). A good pentesting firm (I am happy to connect you with some) will also help you with resources specific to your needs; but you are the best judge of what are the critical components of your tech stack.</p>\n<h2 id=\"penetration-testing\">Penetration Testing <a class=\"direct-link\" href=\"#penetration-testing\">#</a></h2>\n<p>As you get a firmer idea of what you are building and want to do a large launch or enterprise sales, <a href=\"https://owasp.org/Top10/https://en.wikipedia.org/wiki/Penetration_test\">a white-box pentest</a> can also provide a detailed evaluation of your product’s security posture. Your enterprise customers will anyways demand a pentest and using it as an opportunity to further harden your product is a great idea. “White-box” just means that the security testing firm has full read access to your source code.</p>\n<p>With pentests, the usual rule applies: pick two from Good, Fast, Cheap. I recommend always going with good and picking one between fast and cheap. As a startup, opportunity cost is high. A bad pentest can waste your time on security “vulnerabilities” that aren’t real risks and not uncover actual security issues. It’s hard to know which firms provide high quality pentests from their websites: ask the firms for references or talk to other founders for recommendations. I am a fan of <a href=\"https://doyensec.com/\">Doyensec</a>. Regardless of who you pick, aim to invest in a long-term relationship where you can ask them for help with small tests to large-scale full product audits.</p>\n<h1 id=\"customer-assurance\">Customer Assurance <a class=\"direct-link\" href=\"#customer-assurance\">#</a></h1>\n<p>It is not enough to write trustworthy software; it is also important that your customers feel they can trust it. Customer assurance as a function is a broad area with lots of nuances, but, again, there are three categories of work that every enterprise SaaS startup will have to typically tackle.</p>\n<h2 id=\"compliance-certifications\">Compliance Certifications <a class=\"direct-link\" href=\"#compliance-certifications\">#</a></h2>\n<p>Certifications help assure your customers that your organization ensures a minimum baseline of security and governance practices. The most common certification in this category is the SOC2, with startups typically going with a 3-month observation period before switching to one year. For most startups today, the easiest path to getting a SOC2 certification is through one of the numerous SOC2 automation vendors like <a href=\"https://www.vanta.com/\">Vanta</a>. Most startups think about compliance once they are ready to sell to bigger companies, but, for early startups, I recommend reading through <a href=\"https://twitter.com/christinacaci\">Christina’s</a> excellent <a href=\"https://www.vanta.com/blog/five-principles-for-building-a-secure-product\">Before SOC2</a> post or Latacora’s <a href=\"https://latacora.singles/2020/03/12/the-soc-starting.html\">SOC2 Starting 7</a> to avoid a lot of pain later: most of the advice is generally good advice (and matches my advice from earlier in this document).</p>\n<p>One common mistake I have seen founders make is treating SOC2 as a set of requirements they must follow and wasting a lot of time on things that don’t make sense. If you find yourself thinking that a control just doesn’t make sense to you or is too disruptive to your organization, you can likely change it. SOC2 isn’t prescriptive on <em>what</em> you do; rather, auditors help validate and certify that you do what you <em>say you do</em>. Finally, don’t lose sleep over a “finding”: it usually isn’t a big deal unless it is particularly egregious. Some of the biggest companies you know (e.g., AWS) have several findings in their SOC2.</p>\n<h2 id=\"security-questionnaires\">Security Questionnaires <a class=\"direct-link\" href=\"#security-questionnaires\">#</a></h2>\n<p>Even from your earliest customers, you are likely to hit a security review requirement that involves answering security questionnaires. These questionnaires are <a href=\"https://latacora.micro.blog/its-weird-to/\">particularly hated</a> in the industry, but they will likely come up often. Companies like <a href=\"https://securitypalhq.com/\">SecurityPal</a> can help you outsource this problem, but you still will need to help SecurityPal with the first few questionnaires.</p>\n<p>Typical early startups will not be able to achieve full marks on robust questionnaires by large-scale enterprises, but that’s fine. Avoid the trap of questionnaire-driven product development. Instead, I recommend founders prioritize customers who understand you are a startup and want to partner with you as you mature your practices.</p>\n<p>Often, most of the work involved in passing security questionnaires is writing down reasonable, common-sense policies. This is easier than it seems: Gitlab has <a href=\"https://about.gitlab.com/handbook/engineering/security/#-resources\">all their policies</a> public under an MIT license available that you can adapt; or, vendors like <a href=\"https://securitypalhq.com/\">SecurityPal</a> can help you with a basic set of policies.</p>\n<p>For early-stage startups, individual deals can be attractive enough that you fill out questionnaires for each deal. This can get expensive over time. Bigger organizations tend to prefill a number of free questionnaires like the <a href=\"https://github.com/google/vsaq\">Google VSAQ</a>, the <a href=\"https://cloudsecurityalliance.org/blog/2021/09/01/what-is-caiq/\">CAIQ</a>, and other vendor questionnaires like <a href=\"https://www.whistic.com/\">Whistic</a> and <a href=\"https://www.cybergrx.com/\">CyberGRX</a>. This can save you time, especially for smaller deals; I generally recommend waiting for the first time one of your customers asks you to fill these out. Once you have filled one out, proactively include the filled-out questionnaire along with your SOC2 and other certifications as part of the security “package” your sales team provides to prospects. Based on how sensitive the reports are, you can require an NDA or just use GMail confidential mode to share PDFs.</p>\n<h2 id=\"governance%2Fsecurity-inside-your-application\">Governance/Security <em>inside</em> your application <a class=\"direct-link\" href=\"#governance%2Fsecurity-inside-your-application\">#</a></h2>\n<p>Finally, the third category of work in customer assurance involves giving customers control over their data and configuration in your application. Your app can be secure, and your practices audited, but if it is easy to misconfigure and cause a breach, it's an issue that can still negatively impact customer trust.</p>\n<p>Typically, features that help here are put in the “enterprise” tier: this includes things like <a href=\"https://slack.com/help/articles/203772216-SAML-single-sign-on\">enforcing SSO login</a>, enforcing <a href=\"https://help.dropbox.com/teams-admins/admin/manage-team-sharing\">sharing controls</a> for outside-of-org sharing, <a href=\"https://help.dropbox.com/teams-admins/admin/view-activity\">activity/audit log</a> for all access and so on. While it’s impractical to have an answer for all these, I recommend founders spend some time thinking about how it would play out for their early customers. For example, you don’t have to offer logs as part of the product but assure customers that in case of a security incident on the customer’s side, you will work with them to filter out and share logs <em>you</em> have. This can be a great tactical step to unblock deals while you build out these features longer term.</p>\n<h1 id=\"starting-the-security-team\">Starting the security team <a class=\"direct-link\" href=\"#starting-the-security-team\">#</a></h1>\n<p>With luck, you hit product market fit and start scaling. When and how should a company start to build out the security team? I agree with <a href=\"https://scrty.io/\">Magoo’s advice</a>: you likely <a href=\"https://medium.com/starting-up-security/you-dont-need-a-chief-security-officer-3f8d1a76b924\">don’t need a CSO</a> as your first security hire. Instead, a focused hire on a particular sub-function (customer assurance, product security) can be far more effective and keep options open later.</p>\n<p>My advice then is to first wait till you feel like you need a security hire and then, using the discussion above, figure out which sub-function you are trying to solve for. Do you need someone to focus on customer assurance (e.g., compliance and sales security reviews)? Or do you need someone to help with the security of your cloud infrastructure?</p>\n<p>What hiring in security <em>cannot</em> help with is engineering culture; culture is set by the founders and early engineers. An engineering team that values and cares for security will achieve far better outcomes than an engineering team that doesn’t care---hiring in security will not change that. Don’t wait to hire in security to build a culture of security (like any other horizontal function like performance).</p>\n<p>Once you have identified the exact need you want to fill, I recommend posting the role as soon as possible. Security talent is in high demand! But take your time for the first hire: a <em>bad</em> first security hire can do more damage than a missing security team. Non-technical skills are particularly important for the first hire: avoid toxic individuals and only hire someone who believes in the mission of the company.</p>\n",
      "date_published": "2022-03-27T17:00:00-07:00"
    },{
      "id": "https://devd.me/log/posts/kerckhoffs-law/",
      "url": "https://devd.me/log/posts/kerckhoffs-law/",
      "title": "Kerckhoffs’s Law for Security Engineers",
      "content_html": "<p>One of the first lessons in cryptography 101 is <a href=\"https://en.wikipedia.org/wiki/Kerckhoffs%27s_principle\">Kerckhoffs’s law</a>: a cryptosystem should be secure even if everything about the system, except the key, is public knowledge. This is an often-repeated maxim accompanied with “there is no security with obscurity.”</p>\n<p>I always found this framing confusing: it felt inconsistent within itself. “<em>don’t rely on secrecy except for the secrecy of the key</em>” What is so special about keys? Why is it ok to rely on the secrecy of keys and not on secrecy of anything else? And because it is so focused on keys, it’s hard to really take this foundational lesson and apply it in contexts other than cryptographic algorithms.</p>\n<p>In <a href=\"https://www.theatlantic.com/magazine/archive/2002/09/homeland-insecurity/302575/\">Schneier’s framing</a>, the aim here is <em>resilience</em>. Secrecy is a source of brittleness. When something you relied on being secret inevitably leaks, it can be the cause of catastrophic failure. I.e., if you rely on your cryptographic algorithm remaining secret, one day it’s not and suddenly you are in a world of pain.</p>\n<p>This provides a framing of Kerckhoffs’s law that I have found very useful: the security of your system should <em><strong>rely only on secrecy of things you can change easily</strong></em>. Just using open, well-known algorithms for encryption is not enough. You need to be able to change the key easily.</p>\n<p>Usually, this means <em>supporting</em> key rotation in the design—e.g., a encryption scheme that integrates with your key management service also includes the key version in the ciphertext. But, in my experience, a stated design goal to support rotation rarely works. Actually rotating the key regularly is the only way to be sure that you can change the key easily. Ideally, your key management service will automatically rotate secrets at a cadence.</p>\n<p>This is then an easy pattern to look for in security design or review: a cryptosystem where the key is static or not rotated regularly is a source of brittleness almost as bad as having a secret algorithm. Unfortunately, the common framing of Kerckhoffs’s law has meant every engineer will detect and flag the use of an obscure, homebrew crypto algorithm but will happily stamp an encryption scheme that never rotates the key (or worse, <em>can’t</em> rotate the key).</p>\n<p>The reframing also provides a useful lesson for security engineering: relying on secret you are not rotating regularly is a security risk. As much as possible, rely on short-lived secrets and minimize long-lived secrets. For example, for AWS access, do not rely on IAM access keys and secrets; prefer the short-lived credentials provided by role assumption. Ask your vendors to integrate with you using role assumption rather than IAM access keys (something <a href=\"https://aws.amazon.com/blogs/apn/securely-accessing-customer-aws-accounts-with-cross-account-iam-roles/\">even Amazon pushes for</a>).</p>\n<p>I find this philosophy also useful organizationally! A security team unwilling to talk about the architecture or design with customers or researchers is an anti-pattern: the security architecture of an application is not something you can change easily, so sharing it and getting more eyes on it can only help you make secure! Openness and transparency is the mark of a leading security organization. For example, see the Uber security team’s <a href=\"https://eng.uber.com/bug-bounty-map/\">open treasure map</a>. Or, see the Gitlab security team’s goal of being the <a href=\"https://about.gitlab.com/handbook/engineering/security/\">most open security team in the world</a>. Or, just the <a href=\"https://www.chromium.org/Home/chromium-security\">Chrome Security team’s approach</a> overall.</p>\n<p>Finally, it’s useful to remember the real goal here is robust security. Agility is the only way to achieve true robustness, as we learn of new vulnerabilities in systems and algorithms. Just openness in and of itself does not magically make things secure. Rather, openness is a bet that something has had more eyes on it. But even the most reviewed systems fail over time. TLS1.0, RC4, MD5, CBC, RSA — some of the most heavily reviewed systems have been broken over time and the ones we use today will likely be broken some day (hopefully, far) in the future. Can your system adapt?</p>\n<p><em>Thanks to <a href=\"https://tldrsec.com/\">Clint Gibler</a>, Hongyi Hu, Matthew Finifter, Max Burkhardt, Patrick Toomey, Russ Allbery for their feedback. All mistakes are mine and I would love your feedback!</em></p>\n",
      "date_published": "2021-06-03T17:00:00-07:00"
    },{
      "id": "https://devd.me/log/posts/static-analysis/",
      "url": "https://devd.me/log/posts/static-analysis/",
      "title": "Modern Static Analysis: how the best tools empower creativity",
      "content_html": "<p><em><strong>tl;dr</strong>: Historically, heavyweight, slow static analysis tools focused on <strong>finding</strong> vulnerabilities. This approach is fundamentally not the right path for scaling security in modern development. Security teams today need tools that are fast, customizable to our codebases, can easily be added to any part of the SDLC, and are effective at enforcing secure coding patterns to <strong>prevent</strong> vulnerabilities</em></p>\n<p>One of my first loves is program analysis. The essential idea is simple: lets write software that can analyze other software to automatically detect (and thus prevent) bugs, or more relevant to me, security vulnerabilities. My <a href=\"http://webblaze.cs.berkeley.edu/2010/kudzu/kudzu.pdf\">first paper</a> ever was on Javascript dynamic analysis to find client-side bugs like XSS, postMessage flaws and so on. It is then a big surprise to a lot of people that when asked what’s my favorite static analysis tool to integrate into CI, I almost always say <a href=\"http://semgrep.dev/\">Se</a><a href=\"http://semgrep.dev/\">mgrep</a> today (and used to say <code>grep</code> for years).</p>\n<p>Grep and Semgrep are relatively simple and narrowly scoped. Program analysis researchers have done years of amazing work on smart algorithms to infer invariants of a whole program across function calls; while grep runs a regex on the file and Semgrep runs very complicated and smart regexes on the AST (it does more, but let’s assume that for now).</p>\n<p>To understand why I think static analysis as part of an effective SDLC of a modern application often focuses on these simpler tools, let’s walk through a bit of history of the big players in this space and how security engineering needs have evolved. This is, of course, my understanding of this space, but please correct me if I am wrong!</p>\n<p>The most famous static analysis tools common for security/reliability are Coverity, Fortify, and the linters/checks that ship with your compiler (GCC, Clang, Visual Studio toolchain). These tools are absolutely amazing! I was an intern at Coverity and I can say that the amount of technical depth and work that goes into creating these tools is mind-boggling. If you have a large C/C++ code, use Coverity! But, two things stand out about these tools:</p>\n<ul>\n<li><strong>Small set of target languages:</strong> These tools were really designed for a small set of languages (typically C/C++ and/or Java) and each new language is a lot of work. You have to add support for parsing, then integrate semantics of the new language, and then find &amp; write rules that are relatively high signal.</li>\n<li><strong>Powerful default rules:</strong> These tools shipped with a set of rules that were written down by “smart people in an ivory tower” and we had to follow them. The typical static analysis product will not make it easy write your own rules, built on top of the analysis engine. While some tools (notably, Fortify,  Checkmarx) do nowadays support writing custom rules, these are not easy to write. The main “product” for these tools were the bugs found, not the analysis engine to build on top of.</li>\n</ul>\n<p>This made sense: memory unsafe languages like C/C++ were unique in that they were widely used (and still are), and the patterns for the most common security flaws (memory safety) are relatively well known and stable. The challenge was finding these patterns in a high signal manner, given all the undefined behavior in C/C++’s memory model that is commonly used.</p>\n<p>But, modern “DevOps” software development is very different. Two changes in particular are important: surge in number+types of languages and rise of security engineering as a function.</p>\n<ol>\n<li><strong>Surge in languages used</strong></li>\n</ol>\n<p>A standard modern app today, even if it wants to have as few languages as it can, will need to have, at the least, an iOS language (Swift/Objective-C), an Android language (Kotlin or Java), an HTML front end language (Javascript, CSS, HTML), a language to manage your cloud infrastructure (Terraform, Pulumi), config files in a bunch of formats (Dockerfile, package.json), and a server side application language (JS via NPM or Python/Ruby or Go if you are lucky). And that’s the minimum: for most realistic scenarios, with large teams and a micro-services architectures, its typical for server-side infrastructure to actually use 5-6 languages if not more, and the mobile platforms to use 4 languages.</p>\n<p>Worse, a majority of newer languages are <a href=\"https://hackernoon.com/i-finally-understand-static-vs-dynamic-typing-and-you-will-too-ad0c2bd0acc7\">dynamically-typed, interpreted</a> and rely on patterns that are extremely difficult for static analysis. Or, put simply, there are <em><strong>more</strong></em> languages and each language is <em><strong>harder</strong></em> to statically reason about. This means that deep inference based on understanding semantics has struggled to keep up.</p>\n<p>For example, Ruby is a 25 year old language but the common use of meta-programming patterns in Ruby makes static analysis extremely difficult (I know cos I once tried!). And new languages take over at a surprising speed: Terraform is a security lynchpin for a large number of SaaS companies, but it was first launched 6 years ago and the community is already talking about newer languages like Pulumi. The classic static analysis approach of spending years working on getting a deep understanding of one language just doesn’t seem to work here. This has led to popularity of tools tied to a specific language and even framework (e.g., brakeman for Rails applications, gosec for Go apps). These tools typically analyze the abstract syntax tree (or, parse tree) of the code and don’t do deeper inter-procedural value/type analysis.</p>\n<ol start=\"2\">\n<li><strong>Rise of Security Engineering</strong></li>\n</ol>\n<p>Also called “shift left” or “devsecops”, Security is no longer seen as a checklist step after product/eng work. Instead, effective security goes where the developer goes; making the simplest path fast and safe. <strong>The aim is not to find bugs but to prevent vulnerabilities from ever landing in the repo.</strong></p>\n<p>To achieve this, engineering and security teams work together on creating frameworks and libraries for safe use, and security teams help provide input and test these frameworks. Secure coding best practices and patterns are defined and enforced. For example, a common pattern is for the security team to define a <code>secure_encrypt</code> function that natively integrates with the key management in use (including key rotation support) and uses strong authenticated encryption algorithms. Secure coding guidelines typically would require security review of an encryption library other than <code>secure_encrypt</code>.</p>\n<p>Similarly, when a pentest or bug bounty finds a new vulnerability, security engineering teams use the bugs as an input to a broader review of development best-practices: where else are we using this pattern? Can we quickly find these patterns? What’s the secure way to do this and how do we detect/discourage the unsafe pattern?</p>\n<p>As security engineering teams define best practices, they <strong>need a scalable, low-noise mechanism to detect unsafe practices and point developers toward safe coding mechanisms</strong>. These practices are often <em>specific</em> to the company. A security engineer today will often identify bad patterns, write a safe version, and then rely on the static analysis tool to help identify usage of the unsafe pattern in all old and new code. A static analysis engine that doesn’t allow customization and modification is a non-starter. Working with static analysis tools today is no longer a purely operational workflow, <em>it</em>*’*<em>s a creative venture where a security engineer is building something new on top of the analysis engine.</em></p>\n<h3 id=\"creativity-and-static-analysis\">Creativity and Static Analysis <a class=\"direct-link\" href=\"#creativity-and-static-analysis\">#</a></h3>\n<p>What does creativity mean? What does it need? Molly Mielke, <a href=\"https://www.mollymielke.com/cc\">in her amazing thesis</a> on computers and creativity, finds that tools that enable creativity with computers have a few characteristics.</p>\n<blockquote>\n<p>Innovation is largely dependent on the human capacity to think creatively, and there is a strong argument to be made that technology’s primary role is to speed up the creative process…. <strong>Interoperable, moldable, efficient, and community-driven digital creative tools</strong> hold immeasurable potential as co-creators with human beings.</p>\n</blockquote>\n<p>While I encourage you to read her whole thesis to see why this is true, I can personally attest that the tools that have allowed me to do the most have all shared these characteristics (e.g., GitHub). Let’s look at each:</p>\n<ul>\n<li>\n<p><strong>Interoperable tools</strong> are ones that don’t limit your work to a single piece of software’s capabilities. Static analysis tools that are only accessible when I login to their interface; that I can’t integrate with all aspects of a developer’s workflow (develop, test, land, push); all severely constrain what security can do with them. While most static analysis tools now have working integrations, they are still severely limited compared to something like grep/Semgrep. Being open-source binaries I can drop anywhere, grep/Semgrep only need the opportunity to run some code and they can be deployed. With closed engines, I have to ask if they support a particular integration; and I typically can’t run them in places where Internet access isn’t available.</p>\n</li>\n<li>\n<p><strong>Moldable tools</strong> allow customization to fit your needs. As I discussed above, modern security teams need to customize tools to their needs, based on the current secure coding practices. Common customizations include file ignore lists (ignore experimental new apps or code in staging only), allowing certain unsafe tools in certain directories. For example, security engineering might want to ban raw SQL, except in the files that implements the ORM itself. But, those files still need to disallow other patterns (e.g., <code>eval</code>) so we need to customize one specific rule and not disable the whole engine for these files. This is where Semgrep shines: path ignore lists can be customized to each rule, patterns can depend on other patterns (<code>pattern-not-inside</code> and <code>pattern-inside</code> checks), and matches can again be filtered (e.g., regex checks on metavariable matches).</p>\n<p>Molding a tool requires understanding what it is doing. This is again where simplicity of grep/Semgrep wins. When a grep/Semgrep rule has a false positive, it is easy to understand <em>why</em>. In my experience, a typical flow/context/path-sensitive analysis is very frustrating to understand. Is it a false positive or a subtle, true bug? How do you customize something you don’t even understand?</p>\n</li>\n<li>\n<p><strong>Efficient tools</strong> are fast! Writing new rules is iterative. You write a rule that is either too restrictive or too broad, and you iterate until you get it just right. The static analysis engine needs to integrate with the developer’s workflow: a tool that takes hours to run cannot meaningfully integrate with developer workflows either. Grep really wins for this reason; Semgrep is slightly slower but still orders of magnitude faster than the typical tools.</p>\n</li>\n<li>\n<p><strong>Community-driven:</strong> Genius is never alone! True creativity happens when people learn and build upon each other’s work. One of the best things about working in security is the community: all blue/purple teams are in this together and continuously sharing/learning best practices. Historially, static analysis tools have not enabled this community learning/sharing lessons. This is where Semgrep truly wins due to <a href=\"https://semgrep.dev/explore\">its community</a>! Even if Semgrep doesn’t natively support all languages and frameworks, the community will often have a rule for it. And this repository keeps growing! If a new bug/risky-pattern is found, I can write a rule and everyone using Semgrep immediately benefits from it (and as per above, adapt it to their needs). <a href=\"https://kwokchain.com/2021/02/05/atomic-concepts/\">Kevin created this fantastic image in the context of Canva’s success</a>, but it adapts easily to Semgrep.<br>\n<img src=\"https://paper-attachments.dropbox.com/s_306A9A77B1388F284A01E903A4249CA2BEB708149474670A276D4E95386215F2_1619902482943_image.png\" alt=\"Graph on different use cases covered by semgrep, by the community, and by the security team\"></p>\n</li>\n</ul>\n<p>Semgrep core can focus on core, wide impact use cases while the community can serve niche needs. And your security team can work on medium impact, highly niche needs of your product. These three options never really existed before.</p>\n<h3 id=\"conclusion\">Conclusion <a class=\"direct-link\" href=\"#conclusion\">#</a></h3>\n<p>Static analysis for security is different today.  Software is written with many more dynamic, interpreted language. And modern security teams focus on enforcing secure defaults, <em>not</em> finding bugs.</p>\n<p>A static analysis strategy that relies on expensive, heavy integration for each language does not work in this world. Instead, light-weight AST/text-based tools that allow enforcing best practices as defined by the security/engineering teams work best. Moreover, this creative work by security teams needs tools that are interoperable, moldable, efficient, and community driven. I am excited where the Semgrep community goes as it embraces this idea.</p>\n<p>Now, this doesn’t mean smarter static analysis tools are dead. The ideas behind these tools are some of the most powerful ideas in computer science. To be successful, the tools built on these ideas need to embrace that they are creative tools in the hands of their users. How can they make their analysis fast, understandable, and community-driven? <a href=\"https://semmle.com/\">Github/Semmle</a> has a very similar community-driven approach. But the tool lacks the open interoperability, understandability, and speed of Semgrep. At the same time, Semgrep continues to get smarter with support for constant inference, basic flow analysis and so on.</p>\n<p>If Semmle becomes understandable, faster, open; before Semgrep becomes smarter, Semmle could win! But, either way, whatever happens, security teams win! 🙂</p>\n<p><em>Thanks to <a href=\"https://tldrsec.com/\">Clint Gibler</a>, Matthew Finifter, Max Burkhardt, Sean Byrne for their feedback. All mistakes are mine and I would love your feedback.</em></p>\n",
      "date_published": "2021-05-23T17:00:00-07:00"
    }
  ]
}
